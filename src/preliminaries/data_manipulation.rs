use candle_core::{Device, Tensor};
use std::error::Error;

/// ## 2.1.1 入门
///
/// 本节的目标是帮助读者了解并运行一些在阅读本书的过程中会用到的基本数值计算工具。
/// 如果你很难理解一些数学概念或库函数，请不要担心。 后面的章节将通过一些实际的例子来回顾这些内容。
/// 如果你已经具有相关经验，想要深入学习数学内容，可以跳过本节。
///
/// 本教程使用库与python库的对照
///
/// | python库 | rust库 |
/// | --- | --- |
/// | numpy | ndarray |
/// | pandas | polars |
/// | PyTorch | candle |
///
/// 引入 candle 库进行使用。
/// ```shell
/// cargo add --git https://github.com/huggingface/candle.git candle-core
/// ```
///
///<br>
/// 张量（Tensor）表示一个由数值组成的数组，这个数组可能有多个维度。
/// 具有一个轴的张量对应数学上的向量（vector）；
/// 具有两个轴的张量对应数学上的矩阵（matrix）；
/// 具有两个轴以上的张量没有特殊的数学名称。
///
/// 首先，我们可以使用 Tensor::arange 创建一个行向量 x。
/// 这个行向量包含以0开始的前12个数，由于 Tensor::arange 接收的类型不含 i32 ,我们默认创建为f64的浮点数。
/// 张量中的每个值都称为张量的 元素（element）。
/// 例如，张量 x 中有 12 个元素。除非额外指定，新的张量将存储在内存中，并采用基于CPU的计算。
///
/// ```rust
///use candle_core::{Device, Tensor};
///let device = Device::Cpu;
///let x = Tensor::arange(0., 12., &device)?;
///println!("{x}");
/// ```
/// ***
/// [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]
///
/// Tensor[[12], f64]
/// ***
///
///<br>
/// 张量的默认打印包含了值和形状，当然也可以通过张量的shape属性来访问张量（沿每个轴的长度）的形状 。
///
/// ```rust
///use candle_core::{Device, Tensor};
///let device = Device::Cpu;
///let x = Tensor::arange(0., 12., &device)?;
///println!("{:?}",x.shape());
/// ```
/// ***
/// [12]
/// ***
///
///<br>
/// 如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。
///
/// ```rust
///use candle_core::{Device, Tensor};
///let device = Device::Cpu;
///let x = Tensor::arange(0., 12., &device)?;
///println!("{:?}",x.elem_count());
/// ```
/// ***
/// 12
/// ***
///
///<br>
/// 要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数。
/// 例如，可以把张量x从形状为 [12] 的行向量转换为形状为 [3,4] 的矩阵。
/// 这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。
/// 要重点说明一下，虽然张量的形状发生了改变，但其元素值并没有变。
/// 注意，通过改变张量的形状，张量的大小不会改变。
///
/// ```rust
/// use candle_core::{Device, Tensor};
/// let device = Device::Cpu;
/// let x = Tensor::arange(0., 12., &device)?;
/// let x = x.reshape((3, 4))?;
/// println!("{x}");
///```
/// ***
/// [[ 0.,  1.,  2.,  3.],\
///  [ 4.,  5.,  6.,  7.],\
///  [ 8.,  9., 10., 11.]]\
/// Tensor[[3, 4], f64]
/// ***
///
///<br>
/// 有时，我们希望使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵。
/// 我们可以创建一个形状为[2, 3, 4]的张量，其中所有元素都设置为0。代码如下：
///
/// ```rust
/// use candle_core::{Device, Tensor,DType};
/// let device = Device::Cpu;
/// let x = Tensor::zeros((2, 3, 4),DType::F32, &device)?;
/// println!("{x}");
///```
/// ***
/// [[[0., 0., 0., 0.],\
///   [0., 0., 0., 0.],\
///   [0., 0., 0., 0.]],\
///  [[0., 0., 0., 0.],\
///   [0., 0., 0., 0.],\
///   [0., 0., 0., 0.]]]\
/// Tensor[[2, 3, 4], f32]
/// ***
///
///<br>
/// 同样，我们可以创建一个形状为[2, 3, 4]的张量，其中所有元素都设置为1。代码如下：
///
/// ```rust
/// use candle_core::{Device, Tensor,DType};
/// let device = Device::Cpu;
/// let x = Tensor::ones((2, 3, 4),DType::F32, &device)?;
/// println!("{x}");
///```
///***
/// [[[1., 1., 1., 1.],\
///   [1., 1., 1., 1.],\
///   [1., 1., 1., 1.]],\
///  [[1., 1., 1., 1.],\
///   [1., 1., 1., 1.],\
///   [1., 1., 1., 1.]]]\
/// Tensor[[2, 3, 4], f32]\
/// ***
///
///<br>
/// 有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。
/// 例如，当我们构造数组来作为神经网络中的参数时，我们通常会随机初始化参数的值。
/// 以下代码创建一个形状为[3, 4]的张量。
/// 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。
///
/// ```rust
/// use candle_core::{Device, Tensor,DType};
/// let device = Device::Cpu;
/// let x = Tensor::randn(0f32, 1., (3, 4), &device)?;
/// println!("{x}");
///```
/// ***
/// [[-1.2907, -1.2808,  0.2887,  0.8921],\
///  [-1.1277, -0.0230,  2.3441,  0.3280],\
///  [ 0.6468,  1.2457,  1.4576,  1.2184]]\
/// Tensor[[3, 4], f32]
/// ***
///
///<br>
///我们还可以通过提供包含数值的 Vec，来为所需张量中的每个元素赋予确定值。
/// 在这里，元素从前往后、从上到下的填入矩阵。
///
/// ```rust
/// use candle_core::{Device, Tensor,DType};
/// let device = Device::Cpu;
/// let vec = vec![1f64,2.,3.,4.,5.,6.,7.,8.,9.,10.,11.,12.];
/// let x = Tensor::from_vec(vec,(3,4), &device)?;
/// println!("{x}");
///
/// let y = Tensor::new(
///         vec![
///             vec![2., 1., 4., 3.],
///             vec![1., 2., 3., 4.],
///             vec![4., 3., 2., 1.],
///         ],
///         &device,
///     )?;
///println!("{y}");
///```
///***
/// [[ 1.,  2.,  3.,  4.],\
///  [ 5.,  6.,  7.,  8.],\
///  [ 9., 10., 11., 12.]]\
/// Tensor[[3, 4], f64]\
/// [[2., 1., 4., 3.],\
///  [1., 2., 3., 4.],\
///  [4., 3., 2., 1.]]\
/// Tensor[[3, 4], f64]
/// ***
///
///<br>
/// 可以看出candle的张量初始化较为严格，或者说candle库的使用有些严格，这种严格贯彻了rust的设计哲学。
/// 我们要清楚严格是为性能、安全作基石，多加练习，无需抗拒。
// #[test]
pub fn getting_started() -> Result<(), Box<dyn Error>> {
    Ok(())
}

/// ## 2.1.2 运算符
///
///我们的兴趣不仅限于读取数据和写入数据。
///我们想在这些数据上执行数学运算，其中最简单且最有用的操作是按元素（elementwise）运算。
///它们将标准标量运算符应用于数组的每个元素。
///对于将两个数组作为输入的函数，按元素运算将二元运算符应用于两个数组中的每对位置对应的元素。
///我们可以基于任何从标量到标量的函数来创建按元素函数。
///
///(cargo 都从中不支持Latex公式，更复杂的数学说明请参看《动手学深度学习》)
///
///对于任意具有相同形状的张量，
///常见的标准算术运算符（`+`、`-`、`*`、`/`和`**`）都可以被升级为按元素运算。
///我们可以在同一形状的任意两个张量上调用按元素操作。
///在下面的例子中，我们使用逗号来表示一个具有5个元素的元组，其中每个元素都是按元素操作的结果。
///
/// ```rust
/// use candle_core::{Device, Tensor};
/// let device = Device::Cpu;
/// let x = Tensor::new(vec![1., 2., 4., 8.],  &device)?;
/// let y = Tensor::new(vec![2., 2., 2., 2.],  &device)?;
/// println!("{}", (&x + &y)?); //x.add(&y)
/// println!("{}", (&x - &y)?); //x.sub(&y)
/// println!("{}", (&x * &y)?); //x.mul(&y)
/// println!("{}", (&x / &y)?); //x.div(&y)
/// println!("{}", (x.pow(&y))?);
/// ```
/// ***
/// [ 3.,  4.,  6., 10.]\
/// Tensor[[4], f64]\
/// [-1.,  0.,  2.,  6.]\
/// Tensor[[4], f64]\
/// [ 2.,  4.,  8., 16.]\
/// Tensor[[4], f64]\
/// [0.5000, 1.0000, 2.0000, 4.0000]\
/// Tensor[[4], f64]\
/// [ 1.0000,  4.0000, 16.0000, 64.0000]\
/// Tensor[[4], f64]
/// ***
///
///<br>
/// “按元素”方式可以应用更多的计算，包括像求幂这样的一元运算符。
///
/// ```rust
/// use candle_core::{Device, Tensor};
/// let device = Device::Cpu;
/// let x = Tensor::new(vec![1., 2., 4., 8.],  &device)?;
/// println!("{}", &x.exp()?);
/// ```
/// ***
/// [2.7183e0, 7.3891e0, 5.4598e1, 2.9810e3]\
/// Tensor[[4], f64]
/// ***
///
///<br>
///除了按元素计算外，我们还可以执行线性代数运算，包括向量点积和矩阵乘法。 我们将在 2.3节中解释线性代数的重点内容。
///
/// 我们也可以把多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。
/// 我们只需要提供张量列表，并给出沿哪个轴连结。
/// 下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况。
/// 我们可以看到，第一个输出张量的轴-0长度（6）是两个输入张量轴-0长度的总和（3+3）；
/// 第二个输出张量的轴-1长度（8）是两个输入张量轴-1长度的总和（4+4）。
///
/// ```rust
/// use candle_core::{Device, Tensor};
/// let device = Device::Cpu;
/// let x = Tensor::arange(0., 12., &device)?.reshape((3, 4))?;
/// let y = Tensor::new(
///    vec![
///     vec![2., 1., 4., 3.],
///     vec![1., 2., 3., 4.],
///     vec![4., 3., 2., 1.],
///    ],
///    &device,
/// )?;
/// let z = Tensor::cat(&[&x, &y], 0)?;
/// println!("{z}");
/// let z = Tensor::cat(&[x, y], 1)?;
/// println!("{z}");
/// Ok(())
/// ```
///***
/// [[ 0.,  1.,  2.,  3.],\
///  [ 4.,  5.,  6.,  7.],\
///  [ 8.,  9., 10., 11.],\
///  [ 2.,  1.,  4.,  3.],\
///  [ 1.,  2.,  3.,  4.],\
///  [ 4.,  3.,  2.,  1.]]\
/// Tensor[[6, 4], f64]\
/// [[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\
///  [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\
///  [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]\
/// Tensor[[3, 8], f64]
///***
///
/// <br>
///有时，我们想通过逻辑运算符构建二元张量。
/// 以X == Y为例： 对于每个位置，如果X和Y在该位置相等，则新张量中相应项的值为1。
/// 这意味着逻辑语句X == Y在该位置处为真，否则该位置为0。
///
///```rust
/// use candle_core::{Device, Tensor};
/// let device = Device::Cpu;
///     let x = Tensor::arange(0., 12., &device)?.reshape((3, 4))?;
///     let y = Tensor::new(
///         vec![
///             vec![2., 1., 4., 3.],
///             vec![1., 2., 3., 4.],
///             vec![4., 3., 2., 1.],
///         ],
///         &device,
///     )?;
///     let z = x.eq(&y)?;
///     println!("{z}");
/// ```
///***
///[[0, 1, 0, 1],\
///  [0, 0, 0, 0],\
///  [0, 0, 0, 0]]\
/// Tensor[[3, 4], u8]
/// ***
///
/// <br>
///对张量中的所有元素进行求和，会产生一个单元素张量。
///
/// ```rust
/// use candle_core::{Device, Tensor};
///    let device = Device::Cpu;
///     let x = Tensor::arange(0., 12., &device)?.reshape((3, 4))?;
///     println!("{}",x.sum_all()?);
/// ```
/// ***
/// [66.]\
/// Tensor[[], f64]
/// ***
///
// #[test]
pub fn operations() -> Result<(), Box<dyn Error>> {
    Ok(())
}

/// ## 2.1.3 广播机制
///
///在上面的部分中，我们看到了如何在相同形状的两个张量上执行按元素操作。
/// 在某些情况下，即使形状不同，我们仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作。
/// 这种机制的工作方式如下：
/// 1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；
/// 2. 对生成的数组执行按元素操作。
///
/// 在大多数情况下，我们将沿着数组中长度为1的轴进行广播，如下例子：
///
/// ```rust
/// use candle_core::{Device, Tensor};
///    let device = Device::Cpu;
///     let a = Tensor::arange(0., 3., &device)?.reshape((3, 1))?;
///     let b = Tensor::arange(0., 2., &device)?.reshape((1, 2))?;
///     let c = a.broadcast_add(&b)?;
///     println!("{c}");
/// ```
/// ***
///[[0., 1.],\
///  [1., 2.],\
///  [2., 3.]]\
/// Tensor[[3, 2], f64]
/// ***
///
/// <br>
/// 由于a和b分别是（3，1）和（1，2） 矩阵，如果让它们相加，它们的形状不匹配。
/// 我们将两个矩阵广播为一个更大的矩阵，如下所示：矩阵a将复制列， 矩阵b将复制行，然后再按元素相加。
///
// #[test]
pub fn broadcast() -> Result<(), Box<dyn Error>> {
    Ok(())
}

/// ## 2.1.4 索引和切片
///
///就像在任何其他Python数组中一样，张量中的元素可以通过索引访问。
/// 与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1； 可以指定范围以包含第一个元素和最后一个之前的元素。
///
/// 如下所示，我们可以用get(2)选择最后一个元素，可以用i(1..3)选择第二个和第三个元素：
///
/// ``` rust
/// use candle_core::{Device, IndexOp, Tensor};
///     let device = Device::Cpu;
///    let x = Tensor::arange(0., 12., &device)?.reshape((3, 4))?;
///    let result = x.get(2)?;
///    println!("{result}");
///    let result = x.i(1..3)?;
///    println!("{result}");
///    let result = x.narrow(0, 1, 2)?;
///    println!("{result}");
///    let result = x.narrow(1, 1, 2)?;
///    println!("{result}");
/// ```
/// ***
///[ 8.,  9., 10., 11.]\
/// Tensor[[4], f64]\
/// [[ 4.,  5.,  6.,  7.],\
///  [ 8.,  9., 10., 11.]]\
/// Tensor[[2, 4], f64]\
/// [[ 4.,  5.,  6.,  7.],\
///  [ 8.,  9., 10., 11.]]\
/// Tensor[[2, 4], f64]\
/// [[ 1.,  2.],\
///  [ 5.,  6.],\
///  [ 9., 10.]]\
/// Tensor[[3, 2], f64]
/// ***
///
/// <br>
/// candle的Tensor索引或切片还是比较好操作的，但是修改没有较好的支持。
///
///
// #[test]
pub fn indexing_and_slicing() -> Result<(), Box<dyn Error>> {
    Ok(())
}

/// ## 2.1.5 节省内存
///
/// 这是rust开发最不必关注的问题，这是您遵从所有权的无形收获。
pub fn saving_memory() -> Result<(), Box<dyn Error>> {
    Ok(())
}

/// ## 2.1.6 转换为其他对象
///
/// 我们想要将candle的Tensor转换为其他对象，最好的方式是将对应的Vec导出
///
/// ```rust
/// use candle_core::{Device, IndexOp, Tensor};
/// let device = Device::Cpu;
///     let x = Tensor::arange(0., 12., &device)?.reshape((3, 4))?;
///     let result = x.to_vec2::<f64>()?;
///     println!("{:?}", result);
/// ```
/// ***
/// [[0.0, 1.0, 2.0, 3.0], [4.0, 5.0, 6.0, 7.0], [8.0, 9.0, 10.0, 11.0]]
/// ***
///
#[test]
pub fn conversion_to_other_objects() -> Result<(), Box<dyn Error>> {
    let device = Device::Cpu;
    let x = Tensor::arange(0., 12., &device)?.reshape((3, 4))?;
    let result = x.to_vec2::<f64>()?;
    println!("{:?}", result);
    Ok(())
}

/// ## 2.1.7 小结
///
pub fn summary() -> Result<(), Box<dyn Error>> {
    Ok(())
}
